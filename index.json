[{"authors":null,"categories":["adversarial machine learning","research"],"content":" The goal of this paper is to train a machine learning model such that the ML system becomes resistance to adversarial examples. It is a well known fact that neural networks are vulnerable to adversarial examples. Some of the recent works explain that vulnerability of the neural networks is intrinsic. Madry et al. 2017 at MIT investigated how to create robust neural networks with robust optimization. As a result, they found a way to create successful attack and defense techniques based on robust optimization. In this article, I will explain why they used robust optimization, how it worked, and what important techniques they used to create the robust neural networks.\nTable of Contents  Why do they want to do robust optimization? How were they able to achieve training that resulted high resistance to adversarial examples? What are the some math behind this magic?  Why do they want to do robust optimization?   Growth in Machine Learning Application of machine learning has been exponentially increasing in recent years following the development in high computational power and data availability. Recent breakthroughs in computer vision and speech recognition enable us to ride on a self-driving car, make a restaurant or haircut order without touching phone screen, and search what you need on youtube or google simply telling a few words. A new research study \u0026ldquo;Machine Learning Market\u0026rdquo; states that the machine learning market is expected to grow from 1.3 billion USD in 2016 to 40 billion USD in 2025. For these reasons, security of machine learning has become one of the most important fields that needs to be studied.\n Robust neural networks Adversaries often create adversarial exmaples by modifying features of training examples that are close to decision boundary. To create a robust neural networks resistant to these adversarial examples, one technique is to create adversarial examples using training examples close to decision boundary and train the neural networks with them. As a result, the neural networks become more robust.\n Why adversarial robust through robust optimization? Previously, there were many defense techniques including defensive distillation, feature squeezing, and several others. They claim that these techniques don\u0026rsquo;t offer a good understanding of the guarantees they provided. Their a natural saddle point formulation technique guarantees security to broad range of attacks. They were able to create attack and defense mechanisms with this technique. The adversarial training directly relates with optimizing the saddle point problem.\n  How does GANs work?  They make the following contributions:\n Optimization landscape study corresponding to saddle point formulation. Despite non-convexity and non-cavity of its constituent parts, they were able to track and solve the optimization problem using first-order methods. They created a projected gradient attack with the optimization technique using the first-order methods.\n They found the model architecture capacity on adversarial robustness is important. To reliably withstand strong adversarial attacks, networks require a significantly larger capacity than for correctly classifying benign examples only. This shows that a robust decision boundary of the saddle point problem can be significantly more complicated than a decision boundary that simply separates the benign data points.\n Building on the above insights, we train networks on MNIST and CIFAR10 that are robust to a wide range of adversarial attacks. Our approach is based on optimizing the aforementioned saddle point formulation and uses our optimal “first-order adversary”. Our best MNIST model achieves an accuracy of more than 89% against the strongest adversaries in our test suite. In particular, our MNIST network is even robust against white box attacks of an iterative adversary. Our CIFAR10 model achieves an accuracy of 46% against the same adversary. Furthermore, in case of the weaker black box/transfer attacks, our MNIST and CIFAR10 networks achieve the accuracy of more than 95% and 64%, respectively.\n  What are the some math behind this magic?  $ \\theta \\in \\mathbb{R}^{d}$; D - training data distribution; $x \\in \\mathbb{R}^{d}$ training examples; $y \\in [k]$ labels for corresponding examples; $L(\\theta,x,y)$ - loss function\nThe goal is to minimize the risk $E_{(x,y)} \\sim D[L(x,y,\\theta)]$ This ERM is great for classifiers. But, it doesn\u0026rsquo;t provide resistance to adversarial examples\nHow to make it robust? To make the model resistant, they augmented the ERM by following steps.\n They specify the attack model for each training example x, they introduce set of perturbations $S \\in \\mathbb{R}^{d}$ that represents the manipulative power of adversary They modified the population risk $E_{d}[L]$ instead of feeding loss L with samples from original D distribution, they perturb the inputs. In this paper, they only focused on $l_{\\infty}$ bounded attacks.  They introduced the saddle point optimization problem. Inside is a maximization and outside is a minimization problem.\n","date":1547424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547424000,"objectID":"d53600425b53be42decee79b0db9b1e1","permalink":"https://bolor23erdene.github.io/posts/pgd/","publishdate":"2019-01-14T00:00:00Z","relpermalink":"/posts/pgd/","section":"posts","summary":"The goal of this paper is to train a machine learning model such that the ML system becomes resistance to adversarial examples. It is a well known fact that neural networks are vulnerable to adversarial examples. Some of the recent works explain that vulnerability of the neural networks is intrinsic. Madry et al. 2017 at MIT investigated how to create robust neural networks with robust optimization. As a result, they found a way to create successful attack and defense techniques based on robust optimization.","tags":["review"],"title":"Towards Deep Learning Models Resistant to Adversarial Attacks","type":"posts"},{"authors":null,"categories":["adversarial machine learning","research"],"content":" The goal of one of my research is to generate adversarial network traffic that fools the network detection system. I used deep generative model GANs to create the adversarial samples. GANs are known to be best for learning finite amount of training data, interpolating the training data\u0026rsquo;s distribution, and creating samples that are indistinguishable from the original training data. Basically, with GANs, I was able to generate huge amount adversarial traffic by keeping the features that are intrinsic to the attacks and changing the unimportant features so that the traffic bypasses the detection system. In this article, I will explain why you need GANs, how it works, and what challenges you will encounter applying GANs.\nTable of Contents  What is generative model? Why do you need to study GANs? How does GANs work? What are the main challenges of GANs? Wasserstain GANs Improved techniques for training GANs  What is generative model?  Some generative models perform density estimation. The model learns the finite number of samples from the given training data distribution $P_{data}$ and returns an estimate of that distribution $P_{model}$. The end goal is to represent the $P_{data}$ distribution as $P_{model}$ probability distribution.\nWhy do you need to study GANs?   Study high-dimensional probability: Training and generating from generative model is an excellent way to test our ability to manipulate high-dimensional probability distributions. High-dimensional probability distributions are important in applied math and engineering domains.\n Reinforcement learning: Reinforcement learning algorithms are divided into model-based and model-free categories. Model-based algorithms can be incorporated with generative models. Generative models of time-series are able to simulate possible futures for the problem. A generative model can learn a conditional probability distributions over a future states of the world, given with current state and actions.\n Generating data: Generative models can be trained with missing data and can provide prediction on inputs that are missing data. The main idea is to add one more class corresponding to the fake images to the original n classes and train the model. The real-and-fake model also can be trained with known real unlabeled dataset and generated fake dataset.\n  How does GANs work?  The GANs model consists of generator and discriminator models. Generator and discriminator can be seen as counterfeiter and policeman, respectively. The counterfeiter generates fake currency and inject it to market while the policeman evaluates the currency and tells if the currency is real or fake. Due to competition between counterfeiter and policeman, their craftsmanship and evaluation get better and better. At the end, the counterfeiter learns to generate fake currency that is indistinguishable from the real currency.\nWhat are the main challenges of GANs?   Mode Collapse: Mode collapse occurs when the generator is generating samples from only specific type of class. According to Goodfellow et al., mode collapse does not seem to be caused by any particular cost function. In some cases, the Jensen-Shannon divergence caused the mode collapse, however, this does not seem to be the case, because GANs that minimize approximations of $D_{KL}(P_{data}||P_{model})$ face the same same issues, and because the generator often collapses to even fewer modes than would be preferred by the Jensen-Shannon divergence. The mode collapse might be the most important problem with GANs.\n Non-convergence: The GANs optimize two deep models: Generator and Discriminator. Optimizing interrelated two different losses due to generator and discriminator is much more complicated than optimizing loss of conventional deep neural network models. In some cases, although each player might go downhill at each update, it might be the case that one player might make the other one to go uphill on its turn. Eventually, this leads to non-convergence.\n  In the minimax game of GANs, Goodfellow et al. (2014b) showed that the simultaneous gradient descent converges if the updates are made in function space. However, the updates are made in parameter space, so the convexity property needed for the proof doesn\u0026rsquo;t apply. There has not been any theoretical proof that the GAN games should converge or not converge came out yet.\nTo solve these problems, certain methods are introduced such as Wasserstain GAN optimization.\nWasserstain GANS  Learning probability distribution means learning a probability density, which is done by defining a parametric family that maximizes the likelihood on our real data examples ${x^{(i)}}_{i=1}^m$ shown below\n$\\mathop{max}_{\\theta \\in R^{d}}\\frac{1}{m} \\sum_{i=1}^{m} log P_{\\theta} (x^{(i)})$\nThe WGAN paper studied various ways to measure how close the model and real distributions are meaning that various ways to define a distance of divergence $\\rho(P_{\\theta},P_{r})$.\nThe most fundamental difference between such distance is their impact on the convergence of sequences of probability distributions. To optimize the parameter $\\theta$, they define model distribution $P_{\\theta}$ in a way that results the mapping $\\theta \\rightarrow P_{\\theta}$ continuous.\nIn short contributions of the paper:\nTheoretical Analysis\nThey provide a comprehensive theoretical analysis of how the Earth Mover (EM) distance behaves in comparison to popular probability distances and divergences used in the context of learning distributions.\n A form of GAN called WGAN: They define the WGAN that minimizes the reasonable and efficient approximation of the EM distance, and they theoretically show that the corresponding problem is sound.\n WGANs\u0026rsquo; advantages: WGANs does not require maintaining a careful balance in training of the discriminator and the generator, and does not require a careful design of the network architecture either. The mode dropping phenomenon that is typical in GANs is also drastically reduced. The most compelling benefit is the ability to continuously estimate the EM distance by training the discriminator to optimality. Plotting these learning curves is not only useful for debugging and hyperparameter searches, but also correlate remarkably well with the observed same quality.\n  If the real data distribution $P^{r}$ has a density and $P_{\\theta}$ is the distribution of the density defined by the parametric family, then, the problem converts into minimizing the Kullback-Leibler divergence $KL(P_{r}||P_{\\theta})$. For this new problem, we must have the density $P_{\\theta}$ to exist. However, in practice, it is common that we deal with distributions supported by low dimensional manifolds, which leads to negligible intersection between true and model distribution resulting infinite KL divergence. In this case, adding noise to the model distribution fixes the problem, which explains why generative models include a noise component. However, this noise reduces the quality of the samples and makes them poor or blurry. In short, adding noise term is wrong, but is needed to make the maximum likelihood approach work.\nTo solve this problem, without estimating the density $P_{r}$ which may not even exist, we can create a random variable $Z$ with a fixed distribution p(z) and pass that through a parametric function $g_{\\theta}:Z \\rightarrow X$ (a neural network in our case) that directly generates samples following a certain distribution $P_{\\theta}$. By changing $\\theta$, we can change this distribution and make it close to the real data distribution $P_{r}$.\nThis is useful for two reasons. First, unlike densitites, this approach can represent distributions confined to a low dimensional manifold. Second, the ability to easily generate samples is often more useful than knowing the numerical value of the density (for example in image superresolution or semantic segmentation when considering the conditional distribution of the output image given the input image). In general, it is computationally difficult to generate samples given an arbitrary high dimensional density.\nVariational Auto-Encoders (VAEs) and GANs are well known examples of this approach. VAE focus on the approximate likelihood of the examples, they share the limitations of the standard models and need to fiddle with additional noise terms. GANs offer much more flexibility in the definition of the objective function, including Jensen-Shannon, and all f-divergence as well as some exotic combinations. On the other hand, training GANs is well known for being delicate and unstable, for reasons theoretically investigated in.\n","date":1547251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547251200,"objectID":"d043853f9ec3f7eea508dd182c0846d5","permalink":"https://bolor23erdene.github.io/posts/gans/","publishdate":"2019-01-12T00:00:00Z","relpermalink":"/posts/gans/","section":"posts","summary":"The goal of one of my research is to generate adversarial network traffic that fools the network detection system. I used deep generative model GANs to create the adversarial samples. GANs are known to be best for learning finite amount of training data, interpolating the training data\u0026rsquo;s distribution, and creating samples that are indistinguishable from the original training data. Basically, with GANs, I was able to generate huge amount adversarial traffic by keeping the features that are intrinsic to the attacks and changing the unimportant features so that the traffic bypasses the detection system.","tags":["causal diagrams"],"title":"What is GANs?","type":"posts"},{"authors":null,"categories":["causal inference","reading"],"content":" https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols https://lmyint.github.io/post/book-of-why/\nI just finished reading The Book of Why by Judea Pearl and Dana Mackenzie, and I really enjoyed it. I had been wanting to read it for some time now because I know very little about methodology relating to causal diagrams and structure learning. The book provides an overview of the main ideas that formed and historical events that led up to what Pearl calls the \u0026ldquo;Causal Revolution\u0026rdquo;, a burgeoning of the direct interrogation of causation as opposed to its implicit renouncement in science for a period before then. Much of the causal inference methodology that Pearl discusses in the book is his own, namely that of causal diagrams and do-calculus. In light of his own methods, he also discusses techniques that are popular in disciplines such as psychology and economics. He also discusses another major framework for causal inference, the Rubin causal model. In reflecting on the book, I found it useful to organize my thoughts according to major themes I saw in the book.\nTable of Contents  Language and diagrams History Cognition Teaching Conclusions  Language and diagrams  Right from the introduction, Pearl emphasizes the importance of language in science:\n My emphasis on language also comes from a deep conviction that language shapes our thoughts. You cannot answer a question that you cannot ask, and you cannot ask a question that you have no words for. (p. 10)\n I love this quote because it echoes how essential careful language is for humanity\u0026rsquo;s progress. We cannot understand an idea without expressing it in some language in our own minds. We cannot transfer this understanding faithfully to others without carefully crafting language. This crafting of language affects how others understand, consume, act upon, and transfer the idea. And the cycle repeats. Essentially, language governs our intellectual progeny, which has profound scientific, moral, and cultural implications. There is even a growing body of scientific evidence regarding specific ways in which language shapes our thoughts. A TED talk by Lera Boroditsky discusses some of these.\nWhy does Pearl emphasize the importance of language for causal inference? It has to do with precision, and it reminds me of a scene from Lois Lowry\u0026rsquo;s The Giver.\n \u0026ldquo;What is it, Jonas?\u0026rdquo; his father asked.\nHe made himself say the words, though he felt flushed with embarrassment. He had rehearsed them in his mind all the way home from the Annex.\n\u0026ldquo;Do you love me?\u0026rdquo;\nThere was an awkward silence for a moment. Then Father gave a little chuckle. \u0026ldquo;Jonas. You, of all people. Precision of language, please!\u0026rdquo;\n Earlier in the book it is revealed that the reason for the strict adherence to precision of language in Jonas\u0026rsquo;s community is to avoid unintentional lies that can come about through exaggeration or misinterpretation. We learn quickly in the story that this precision of language creates a dystopia, devoid of true feeling and the emotions that make up a beautiful human life.\nA bleak picture in the case of The Giver, but the existence of a language that allows for precise expression is indispensable when it comes to science! Consider the following epidemiological investigation: we want to know how the consumption of red meat influences risk for colon cancer. There are two questions that we might think of quickly.\n Does eating red meat cause an increase in colon cancer risk? How much red meat consumption is needed to increase the risk of colon cancer?  My impression is that the first question is how the majority of the public perceives a causal effect. Does exposure cause outcome? Pearl explains that this conventional way of thinking about causal analysis is really not the goal of the field at all:\n Many people still make Niles\u0026rsquo;s mistake of thinking that the goal of causal analysis is to prove that X is a cause of Y or else to find the cause of Y from scratch. That is the problem of causal discovery. (p. 79)\n (Niles was a critic of path analysis/causal diagrams.) The goal of causal analysis is to quantitatively estimate causal effects while fully capturing the state of the analyst\u0026rsquo;s current knowledge. The full capturing of current knowledge is achieved by drawing a causal diagram.\nThe second question, though quantitative, is still imprecise. It gets more at the estimation goal of causal analysis, but its imprecision leads to individual interpretations of the best way to proceed (essentially researcher degrees of freedom). Certainly there will be differences between individuals in terms of what they feel is the current state of knowledge on a subject. That is, experts may disagree on their causal diagrams. This disagreement is ok as long as their working set of assumptions (the causal diagrams) are made explicit. Usually when researchers ask a causal question like number 2, researcher degrees of freedom abound in both the variables considered and the manner in which the variables are handled in the analytic method.\nBoth of these issues can be avoided by using causal diagrams and the accompanying language of do-calculus. Causal diagrams are a means of precisely representing current knowledge. Do-calculus consists of a set of rules that allow us to express a causal quantity that we want to estimate in terms of quantities that can be computed from data. That is, it is a set of rules that allows us to express the effect of an intervention in terms of observational data quantities. An interventional effect is specified with the do-operator as with $P(Y \\mid do(X))$ to indicate a deliberate intervention. This is usually quite different from the observational quantity $P(Y \\mid X)$ as a classic confounding example illustrates. Let $Y$ denote reading ability and $X$ denote shoe size. We all know that age confounds the relationship as it is a cause of both shoe size and reading ability (provided the individual benefits from education). Were it not completely insane, intervening on shoe size would not change $P(Y \\mid do(X))$, but the observational quantity $P(Y \\mid X)$ does change as $X$ changes.\nIt was not intuitive for me that the effect of an intervention that has not actually been carried out could be estimated from observational data, but Pearl builds up these ideas in The Book of Why to explain (in Chapter 7) that 3 rules of do-calculus suffice for determining if a particular causal effect can be estimated from observation data given a causal diagram. This blog post gives more technical details about causal diagrams and do-calculus, and the introductory paper cited in that post explains the 3 rules in detail.\nThe combination of causal diagrams and do-calculus is a powerful idea for me because of the precision of language that it offers for making causal queries. We first must lay our assumptions bare with a causal diagram. This was not a hard point to sell me on because I am already a firm believer in the power of network methods to organize domain knowledge. Do-calculus on the other hand is quite surprising. Still, the 3 rules provide clear guidelines on how to express a causal effect from observational data, and this clarity in allowable expressions is for me a compelling motivator for their use. Pearl mentions in the book that these rules have been algorithmized, and in my brief searching, I have found the R package called daggity that seems to implement the rules of do-calculus.\nHistory  Another major theme of this book is understanding history. One entire chapter is devoted to tracing the history of how causal inference came to be. Pearl and Mackenzie start by recounting the tale of Francis Galton, a British scientist who was on a quest to understand the genetic determinants of features like height and intelligence. He eventually stumbled upon the phenomenon of regression to the mean and saw it as a physical, casual process because it was able to reconcile some peculiar features of models that he had developed for height distributions across generations. However, he eventually grew dissatisfied with the idea after finding that the phenomenon persisted regardless of which variable was treated as the causal agent. He was never able to resolve his initial causal queries about genetic determinants, but he did pass on ideas of scatterplots and correlation to future generations of statisticians. In particular, Karl Pearson took to the idea of correlation quite excitedly and came to eschew ideas of causality, which he viewed as imprecise and vague in contrast to his clean, mathematized correlation coefficient. Such was a major force behind the lack of causality research in statistics for some time. Pearl and Mackenzie end this historical chapter with the tale of Sewall Wright, who seems to have been one of the first to come up with the idea of using causal diagrams. Through Wright\u0026rsquo;s tale we see a reemergence of the willingness to study casuality rigorously and quantitatively.\nThis historical discussion is fascinating because it allows us (with our hindsight goggles on) to understand why research progressed the way that it did. Through understanding the personalities and culture of these historical figures, we can understand why certain ideas were pursued, why shortcomings arose, and hopefully mediate ourselves to be better scientists because of this understanding.\nCognition  The importance of an awareness of human cognition is also a recurring idea in the book. Pearl motivates his journey through causal inference with his interests in artificial intelligence, and he claims that causal inference methods should ideally try to emulate the powerful causal reasoning faculties within our own minds that stem from simply asking the question: why? I like the apparent simplicity of this. It is easy to see how asking this question could give rise to causal diagrams. Each \u0026ldquo;because\u0026rdquo; becomes a directed connection from nodes that represent variables in our \u0026ldquo;because\u0026rdquo; statement. Still, at the same time, I wondered: should there not be some higher standard to which causal inference methods should aspire? Why simply aim to replicate human reasoning? Shouldn\u0026rsquo;t we strive for our methods to achieve something more than just human reasoning in some sense? After thinking about this, I feel that these goals are too lofty. We humans are limited by our capabilities, so even if causal inference methods could achieve beyond-human reasoning, we wouldn\u0026rsquo;t know that they were. Given a method that produces some results, we would still evaluate the method by asking, \u0026ldquo;Do those results make sense?\u0026rdquo; We would still be using our (powerful) causal reasoning capabilities to make sense of the results generated by the method. Thus even if some deeper meaning was somehow conveyed by the method, the meaning we would be able to extract from it is limited by the framework of our understanding. I feel that Pearl\u0026rsquo;s claims about using human reasoning as a gold standard for causal inference methods is reasonable. This thinking also reaffirms my belief in the importance of understanding how humans interact with the tools we develop, such as through the fields of ergonomics, human-computer interaction, human-data interaction.\nAn awareness of human cognition is explored most extensively in a chapter on several paradoxes: the Monty Hall problem, Berkson\u0026rsquo;s paradox, Simpson\u0026rsquo;s paradox, and Lord\u0026rsquo;s paradox. I had actualy never heard of Berkson\u0026rsquo;s paradox, but it is the appearance of an association in a subpopulation that is not seen in the general population. Pearl explores all of these paradoxes in light of causal diagrams, and I actually did find it helpful to view these problems with this causal lens. The causal diagrams were useful in generalizing the structure of the situations governing the paradoxes, which I think is helpful in recognizing when they occur. Further, Pearl lays forth a reasonable set of criteria for dealing with paradoxes:\n Any claim to resolve a paradox (especially one that is decades old) should meet some basic criteria. First, as I said above in connection with the Monty Hall paradox, it should explain why people find the paradox surprising or unbelievable. Second, it should identify the class of scenarios in which the paradox can occur. Third, it should inform us of scenarios, if any, in which the paradox cannot occur. Finally, when the paradox does occur, and we have to make a choice between two plausible yet contradictory statements, it should tell us which statement is correct. (p. 202)\n Teaching  By its nature, the book aims to inform readers about the development of and about central ideas in causal inference, but teaching and pedagogy are not direct themes of the book. That being said, I was amazed at how appropriate the writing of the book is for a classroom textbook. There are a lot of great thought experiments, historical examples, and activities to engage students at the undergraduate level and beyond. In particular, the chapters that recount the evolution of the smoking-lung cancer debate (Chapter 5) and that explore \u0026ldquo;statistical\u0026rdquo; paradoxes through a causal lens (Chapter 6) are great sources of classroom content.\nConclusions  I highly recommend this book to anyone who cares about science. Even if causal inference isn\u0026rsquo;t an area of interest for you, the ideas in this book are important for understanding the causal research that we otherwise consume or hear about. Pearl is very invested in these ideas, so the language in the book is very enthusiastically in favor of these methods. I can see how this might irritate some readers, but I found that the ideas he presented were compelling and interesting in their own right. Certainly these methods are not a panacea, but I do believe that they can be quite useful. Reading the book has motivated me to continue learning about these topics, and I hope that I can eventually fully understand the answers to some questions I was left with:\n Is there no reconciliation at all for Rubin causal model type methods and do-calculus methods? How can causal diagrams and do-calculus be used to study networks that evove with time? How is interference between units handled? How can we measure the causal effect of several variables simultaneously? I have heard of edges being random variables in the graphical model literature. (i.e. Arrows can point to arrows.) Is this part of the do-calculus framework?  ","date":1532476800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532476800,"objectID":"c767236291c15e0283e20084283af989","permalink":"https://bolor23erdene.github.io/posts/book-of-why/","publishdate":"2018-07-25T00:00:00Z","relpermalink":"/posts/book-of-why/","section":"posts","summary":"https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols https://lmyint.github.io/post/book-of-why/\nI just finished reading The Book of Why by Judea Pearl and Dana Mackenzie, and I really enjoyed it. I had been wanting to read it for some time now because I know very little about methodology relating to causal diagrams and structure learning. The book provides an overview of the main ideas that formed and historical events that led up to what Pearl calls the \u0026ldquo;Causal Revolution\u0026rdquo;, a burgeoning of the direct interrogation of causation as opposed to its implicit renouncement in science for a period before then.","tags":["causal diagrams"],"title":"The Book of Why","type":"posts"}]
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bolor-Erdene Zolbayar on Bolor-Erdene Zolbayar</title>
    <link>https://bolor23erdene.github.io/</link>
    <description>Recent content in Bolor-Erdene Zolbayar on Bolor-Erdene Zolbayar</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>What is GANs?</title>
      <link>https://bolor23erdene.github.io/posts/gans/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bolor23erdene.github.io/posts/gans/</guid>
      <description>

&lt;p&gt;The goal of one of my research is to generate adversarial network traffic that fools the network detection system. I used deep generative model GANs to create the adversarial samples. GANs are known to be best for learning finite amount of training data, interpolating the training data&amp;rsquo;s distribution, and creating samples that are indistinguishable from the original training data. Basically, with GANs, I was able to generate huge amount adversarial traffic by keeping the features that are intrinsic to the attacks and changing the unimportant features so that the traffic bypasses the detection system. In this article, I will explain why you need GANs, how it works, and what challenges you will encounter applying GANs.&lt;/p&gt;

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#generative-model&#34;&gt;What is generative model?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#why&#34;&gt;Why do you need to study GANs?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how&#34;&gt;How does GANs work?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what&#34;&gt;What are the main challenges of GANs?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#paper1&#34;&gt;Wasserstain GANs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#paper2&#34;&gt;Improved techniques for training GANs&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;what-is-generative-model-a-id-generative-model-a&#34;&gt;What is generative model? &lt;a id=&#34;generative-model&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Some generative models perform density estimation. The model learns the finite number of samples from the given training data distribution $Pdata$ and returns an estimate of that distribution $P&lt;em&gt;{model}$. The end goal is to represent the $P&lt;/em&gt;{data}$ distribution as $P_{model}$ probability distribution.&lt;/p&gt;

&lt;h2 id=&#34;why-do-you-need-to-study-gans-a-id-why-a&#34;&gt;Why do you need to study GANs? &lt;a id=&#34;why&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Study high-dimensional probability&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Training and generating from generative model is an excellent way to test our ability to manipulate high-dimensional probability distributions. High-dimensional probability distributions are important in applied math and engineering domains.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Reinforcement learning&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Reinforcement learning algorithms are divided into model-based and model-free categories. Model-based algorithms can be incorporated with generative models. Generative models of time-series are able to simulate possible futures for the problem. A generative model can learn a conditional probability distributions over a future states of the world, given with current state and actions.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Generating data&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Generative models can be trained with missing data and can provide prediction on inputs that are missing data. The main idea is to add one more class corresponding to the fake images to the original n classes and train the model. The real-and-fake model also can be trained with known real unlabeled dataset and generated fake dataset.&lt;/p&gt;

&lt;h2 id=&#34;how-does-gans-work-a-id-how-a&#34;&gt;How does GANs work? &lt;a id=&#34;how&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The GANs model consists of generator and discriminator models. Generator and discriminator can be seen as counterfeiter and policeman, respectively. The counterfeiter generates fake currency and inject it to market while the policeman evaluates the currency and tells if the currency is real or fake. Due to competition between counterfeiter and policeman, their craftsmanship and evaluation get better and better. At the end, the counterfeiter learns to generate fake currency that is indistinguishable from the real currency.&lt;/p&gt;

&lt;h2 id=&#34;what-are-the-main-challenges-of-gans-a-id-what-a&#34;&gt;What are the main challenges of GANs &lt;a id=&#34;what&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Mode Collapse
Mode collapse occurs when the generator is generating samples from only specific type of class. According to Goodfellow et al., mode collapse does not seem to be caused by any particular cost function. In some cases, the Jensen-Shannon divergence caused the mode collapse, however, this does not seem to be the case, because GANs that minimize approximations of $D&lt;em&gt;{KL}(P&lt;/em&gt;{data}||P_{model})$ face the same same issues, and because the generator often collapses to even fewer modes than would be preferred by the Jensen-Shannon divergence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The mode collapse might be the most important problem with GANs.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Non-convergence
The GANs optimize two deep models: Generator and Discriminator. Optimizing interrelated two different losses due to generator and discriminator is much more complicated than optimizing loss of conventional deep neural network models. In some cases, although each player might go downhill at each update, it might be the case that one player might make the other one to go uphill on its turn. Eventually, this leads to non-convergence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In the minimax game of GANs, Goodfellow et al. (2014b) showed that the simultaneous gradient descent converges if the updates are made in function space. However, the updates are made in parameter space, so the convexity property needed for the proof doesn&amp;rsquo;t apply. There has not been any theoretical proof that the GAN games should converge or not converge came out yet.&lt;/p&gt;

&lt;p&gt;To solve these problems, certain methods are introduced such as Wasserstain GAN optimization.&lt;/p&gt;

&lt;h2 id=&#34;wasserstain-gans-a-id-paper1-a&#34;&gt;Wasserstain GANS &lt;a id=&#34;paper1&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Learning probability distribution means learning a probability density, which is done by defining a parametric family that maximizes the likelihood on our real data examples ${x^{(i)}}_{i=1}^m$ shown as Eq \ref{eq:1}:&lt;/p&gt;

&lt;p&gt;\begin{equation} \label{eq:1}
\mathop{max}&lt;em&gt;{\theta \in R^{d}}\frac{1}{m} \sum&lt;/em&gt;{i=1}^{m} log P_{\theta} (x^{(i)})
\end{equation}&lt;/p&gt;

&lt;p&gt;The WGAN paper studied various ways to measure how close the model and real distributions are meaning that various ways to define a distance of divergence $\rho(P&lt;em&gt;{\theta},P&lt;/em&gt;{r})$.&lt;/p&gt;

&lt;p&gt;The most fundamental difference between such distance is their impact on the convergence of sequences of probability distributions. To optimize the parameter $\theta$, they define model distribution $P&lt;em&gt;{\theta}$ in a way that results the mapping $\theta-&amp;gt;P&lt;/em&gt;{\theta}$ continuous.&lt;/p&gt;

&lt;p&gt;In short contributions of the paper:&lt;/p&gt;

&lt;p&gt;\begin{itemize}
\item{Theoretical Analysis}&lt;/p&gt;

&lt;p&gt;They provide a comprehensive theoretical analysis of how the Earth Mover (EM) distance behaves in comparison to popular probability distances and divergences used in the context of learning distributions.&lt;/p&gt;

&lt;p&gt;\item{A form of GAN called WGAN}&lt;/p&gt;

&lt;p&gt;They defines the WGAN that minimizes the reasonable and efficient approximation of the EM distance, and they theoretically show that the corresponding problem is sound.&lt;/p&gt;

&lt;p&gt;\item{WGANs&amp;rsquo; advantages}&lt;/p&gt;

&lt;p&gt;WGANs does not require maintaining a careful balance in training of the discriminator and the generator, and does not require a careful design of the network architecture either.&lt;/p&gt;

&lt;p&gt;The mode dropping phenomenon that is typical in GANs is also drastically reduced.&lt;/p&gt;

&lt;p&gt;The most compelling benefit is the ability to continuously estimate the EM distance by training the discriminator to optimality. Plotting these learning curves is not only useful for debugging and hyperparameter searches, but also correlate remarkably well with the observed same quality.&lt;/p&gt;

&lt;p&gt;\end{itemize}&lt;/p&gt;

&lt;p&gt;If the real data distribution $P^{r}$ has a density and $P&lt;em&gt;{\theta}$ is the distribution of the density defined by the parametric family, then, the problem converts into minimizing the Kullback-Leibler divergence $KL(P&lt;/em&gt;{r}||P&lt;em&gt;{\theta})$. For this new problem, we must have the density $P&lt;/em&gt;{\theta}$ to exist. However, in practice, it is common that we deal with distributions supported by low dimensional manifolds, which leads to negligible intersection between true and model distribution resulting infinite KL divergence. In this case, adding noise to the model distribution fixes the problem, which explains why generative models include a noise component. However, this noise reduces the quality of the samples and makes them poor or blurry. In short, adding noise term is wrong, but is needed to make the maximum likelihood approach work.&lt;/p&gt;

&lt;p&gt;To solve this problem, without estimating the density $P&lt;em&gt;{r}$ which may not even exist, we can create a random variable $Z$ with a fixed distribution p(z) and pass that through a parametric function $g&lt;/em&gt;{\theta}:Z -&amp;gt; X$ (a neural network in our case)
 that directly generates samples following a certain distribution $P&lt;em&gt;{\theta}$. By changing $\theta$, we can change this distribution and make it close to the real data distribution $P&lt;/em&gt;{r}$.&lt;/p&gt;

&lt;p&gt;This is useful for two reasons. First, unlike densitites, this approach can represent distributions confined to a low dimensional manifold. Second, the ability to easily generate samples is often more useful than knowing the numerical value of the density (for example in image superresolution or semantic segmentation when considering the conditional distribution of the output image given the input image). In general, it is computationally difficult to generate samples given an arbitrary high dimensional density.&lt;/p&gt;

&lt;p&gt;Variational Auto-Encoders (VAEs) and GANs are well known examples of this approach. VAE focus on the approximate likelihood of the examples, they share the limitations of the standard models and need to fiddle with additional noise terms. GANs offer much more flexibility in the definition of the objective function, including Jensen-Shannon, and all f-divergence as well as some exotic combinations. On the other hand, training GANs is well known for being delicate and unstable, for reasons theoretically investigated in.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Book of Why</title>
      <link>https://bolor23erdene.github.io/posts/book-of-why/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bolor23erdene.github.io/posts/book-of-why/</guid>
      <description>

&lt;p&gt;I just finished reading &lt;em&gt;The Book of Why&lt;/em&gt; by Judea Pearl and Dana Mackenzie, and I really enjoyed it. I had been wanting to read it for some time now because I know very little about methodology relating to causal diagrams and structure learning. The book provides an overview of the main ideas that formed and historical events that led up to what Pearl calls the &amp;ldquo;Causal Revolution&amp;rdquo;, a burgeoning of the direct interrogation of causation as opposed to its implicit renouncement in science for a period before then. Much of the causal inference methodology that Pearl discusses in the book is his own, namely that of causal diagrams and &lt;em&gt;do&lt;/em&gt;-calculus. In light of his own methods, he also discusses techniques that are popular in disciplines such as psychology and economics. He also discusses another major framework for causal inference, the Rubin causal model. In reflecting on the book, I found it useful to organize my thoughts according to major themes I saw in the book.&lt;/p&gt;

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#language-diagrams&#34;&gt;Language and diagrams&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#history&#34;&gt;History&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cognition&#34;&gt;Cognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#teaching&#34;&gt;Teaching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;language-and-diagrams-a-id-language-diagrams-a&#34;&gt;Language and diagrams &lt;a id=&#34;language-diagrams&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Right from the introduction, Pearl emphasizes the importance of language in science:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;My emphasis on language also comes from a deep conviction that language
shapes our thoughts. You cannot answer a question that you cannot ask,
and you cannot ask a question that you have no words for. (p. 10)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I love this quote because it echoes how essential careful language is for humanity&amp;rsquo;s progress. We cannot understand an idea without expressing it in some language in our own minds. We cannot transfer this understanding faithfully to others without carefully crafting language. This crafting of language affects how others understand, consume, act upon, and transfer the idea. And the cycle repeats. Essentially, language governs our intellectual progeny, which has profound scientific, moral, and cultural implications. There is even a growing body of scientific evidence regarding specific ways in which language shapes our thoughts. A &lt;a href=&#34;https://www.ted.com/talks/lera_boroditsky_how_language_shapes_the_way_we_think&#34; target=&#34;_blank&#34;&gt;TED talk by Lera Boroditsky&lt;/a&gt; discusses some of these.&lt;/p&gt;

&lt;p&gt;Why does Pearl emphasize the importance of language for causal inference? It has to do with precision, and it reminds me of a scene from Lois Lowry&amp;rsquo;s &lt;em&gt;The Giver&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;What is it, Jonas?&amp;rdquo; his father asked.&lt;/p&gt;

&lt;p&gt;He made himself say the words, though he felt flushed with
embarrassment. He had rehearsed them in his mind all the way
home from the Annex.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Do you love me?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;There was an awkward silence for a moment. Then Father gave a
little chuckle. &amp;ldquo;Jonas. You, of all people. Precision of
language, please!&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Earlier in the book it is revealed that the reason for the strict adherence to precision of language in Jonas&amp;rsquo;s community is to avoid unintentional lies that can come about through exaggeration or misinterpretation. We learn quickly in the story that this precision of language creates a dystopia, devoid of true feeling and the emotions that make up a beautiful human life.&lt;/p&gt;

&lt;p&gt;A bleak picture in the case of &lt;em&gt;The Giver&lt;/em&gt;, but the existence of a language that allows for precise expression is indispensable when it comes to science! Consider the following epidemiological investigation: we want to know how the consumption of red meat influences risk for colon cancer. There are two questions that we might think of quickly.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Does eating red meat cause an increase in colon cancer risk?&lt;/li&gt;
&lt;li&gt;How much red meat consumption is needed to increase the risk of colon cancer?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;My impression is that the first question is how the majority of the public perceives a causal effect. &lt;em&gt;Does&lt;/em&gt; exposure cause outcome? Pearl explains that this conventional way of thinking about causal analysis is really not the goal of the field at all:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Many people still make Niles&amp;rsquo;s mistake of thinking that the goal
of causal analysis is to prove that X is a cause of Y or else to
find the cause of Y from scratch. That is the problem of causal
discovery. (p. 79)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(Niles was a critic of path analysis/causal diagrams.) The goal of causal analysis is to quantitatively estimate causal effects while fully capturing the state of the analyst&amp;rsquo;s current knowledge. The full capturing of current knowledge is achieved by drawing a causal diagram.&lt;/p&gt;

&lt;p&gt;The second question, though quantitative, is still imprecise. It gets more at the estimation goal of causal analysis, but its imprecision leads to individual interpretations of the best way to proceed (essentially researcher degrees of freedom). Certainly there will be differences between individuals in terms of what they feel is the current state of knowledge on a subject. That is, experts may disagree on their causal diagrams. This disagreement is ok as long as their working set of assumptions (the causal diagrams) are made explicit. Usually when researchers ask a causal question like number 2, researcher degrees of freedom abound in both the variables considered and the manner in which the variables are handled in the analytic method.&lt;/p&gt;

&lt;p&gt;Both of these issues can be avoided by using causal diagrams and the accompanying language of &lt;em&gt;do&lt;/em&gt;-calculus. Causal diagrams are a means of precisely representing current knowledge. &lt;em&gt;Do&lt;/em&gt;-calculus consists of a set of rules that allow us to express a causal quantity that we want to estimate in terms of quantities that can be computed from data. That is, it is a set of rules that allows us to express the effect of an &lt;strong&gt;intervention&lt;/strong&gt; in terms of observational data quantities. An interventional effect is specified with the &lt;em&gt;do&lt;/em&gt;-operator as with $P(Y \mid do(X))$ to indicate a deliberate intervention. This is usually quite different from the observational quantity $P(Y \mid X)$ as a classic confounding example illustrates. Let $Y$ denote reading ability and $X$ denote shoe size. We all know that age confounds the relationship as it is a cause of both shoe size and reading ability (provided the individual benefits from education). Were it not completely insane, intervening on shoe size would not change $P(Y \mid do(X))$, but the observational quantity $P(Y \mid X)$ does change as $X$ changes.&lt;/p&gt;

&lt;p&gt;It was not intuitive for me that the effect of an intervention that has not actually been carried out could be estimated from observational data, but Pearl builds up these ideas in &lt;em&gt;The Book of Why&lt;/em&gt; to explain (in Chapter 7) that 3 rules of &lt;em&gt;do&lt;/em&gt;-calculus suffice for determining if a particular causal effect can be estimated from observation data given a causal diagram. &lt;a href=&#34;https://www.inference.vc/untitled/&#34; target=&#34;_blank&#34;&gt;This blog post&lt;/a&gt; gives more technical details about causal diagrams and &lt;em&gt;do&lt;/em&gt;-calculus, and the &lt;a href=&#34;https://arxiv.org/abs/1305.5506&#34; target=&#34;_blank&#34;&gt;introductory paper&lt;/a&gt; cited in that post explains the 3 rules in detail.&lt;/p&gt;

&lt;p&gt;The combination of causal diagrams and &lt;em&gt;do&lt;/em&gt;-calculus is a powerful idea for me because of the precision of language that it offers for making causal queries. We first must lay our assumptions bare with a causal diagram. This was not a hard point to sell me on because I am already a firm believer in the power of network methods to organize domain knowledge. &lt;em&gt;Do&lt;/em&gt;-calculus on the other hand is quite surprising. Still, the 3 rules provide clear guidelines on how to express a causal effect from observational data, and this clarity in allowable expressions is for me a compelling motivator for their use. Pearl mentions in the book that these rules have been algorithmized, and in my brief searching, I have found the R package called &lt;a href=&#34;http://www.dagitty.net/&#34; target=&#34;_blank&#34;&gt;daggity&lt;/a&gt; that seems to implement the rules of &lt;em&gt;do&lt;/em&gt;-calculus.&lt;/p&gt;

&lt;h2 id=&#34;history-a-id-history-a&#34;&gt;History &lt;a id=&#34;history&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Another major theme of this book is understanding history. One entire chapter is devoted to tracing the history of how causal inference came to be. Pearl and Mackenzie start by recounting the tale of Francis Galton, a British scientist who was on a quest to understand the genetic determinants of features like height and intelligence. He eventually stumbled upon the phenomenon of regression to the mean and saw it as a physical, casual process because it was able to reconcile some peculiar features of models that he had developed for height distributions across generations. However, he eventually grew dissatisfied with the idea after finding that the phenomenon persisted regardless of which variable was treated as the causal agent. He was never able to resolve his initial causal queries about genetic determinants, but he did pass on ideas of scatterplots and correlation to future generations of statisticians. In particular, Karl Pearson took to the idea of correlation quite excitedly and came to eschew ideas of causality, which he viewed as imprecise and vague in contrast to his clean, mathematized correlation coefficient. Such was a major force behind the lack of causality research in statistics for some time. Pearl and Mackenzie end this historical chapter with the tale of Sewall Wright, who seems to have been one of the first to come up with the idea of using causal diagrams. Through Wright&amp;rsquo;s tale we see a reemergence of the willingness to study casuality rigorously and quantitatively.&lt;/p&gt;

&lt;p&gt;This historical discussion is fascinating because it allows us (with our hindsight goggles on) to understand why research progressed the way that it did. Through understanding the personalities and culture of these historical figures, we can understand why certain ideas were pursued, why shortcomings arose, and hopefully mediate ourselves to be better scientists because of this understanding.&lt;/p&gt;

&lt;h2 id=&#34;cognition-a-id-cognition-a&#34;&gt;Cognition &lt;a id=&#34;cognition&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The importance of an awareness of human cognition is also a recurring idea in the book. Pearl motivates his journey through causal inference with his interests in artificial intelligence, and he claims that causal inference methods should ideally try to emulate the powerful causal reasoning faculties within our own minds that stem from simply asking the question: why? I like the apparent simplicity of this. It is easy to see how asking this question could give rise to causal diagrams. Each &amp;ldquo;because&amp;rdquo; becomes a directed connection from nodes that represent variables in our &amp;ldquo;because&amp;rdquo; statement. Still, at the same time, I wondered: should there not be some higher standard to which causal inference methods should aspire? Why simply aim to replicate human reasoning? Shouldn&amp;rsquo;t we strive for our methods to achieve something &lt;em&gt;more&lt;/em&gt; than just human reasoning in some sense? After thinking about this, I feel that these goals are too lofty. We humans are limited by our capabilities, so even if causal inference methods could achieve beyond-human reasoning, we wouldn&amp;rsquo;t &lt;em&gt;know&lt;/em&gt; that they were. Given a method that produces some results, we would still evaluate the method by asking, &amp;ldquo;Do those results make sense?&amp;rdquo; We would still be using our (powerful) causal reasoning capabilities to make sense of the results generated by the method. Thus even if some deeper meaning was somehow conveyed by the method, the meaning we would be able to extract from it is limited by the framework of our understanding. I feel that Pearl&amp;rsquo;s claims about using human reasoning as a gold standard for causal inference methods is reasonable. This thinking also reaffirms my belief in the importance of understanding how humans interact with the tools we develop, such as through the fields of ergonomics, human-computer interaction, human-data interaction.&lt;/p&gt;

&lt;p&gt;An awareness of human cognition is explored most extensively in a chapter on several paradoxes: the Monty Hall problem, Berkson&amp;rsquo;s paradox, Simpson&amp;rsquo;s paradox, and Lord&amp;rsquo;s paradox. I had actualy never heard of Berkson&amp;rsquo;s paradox, but it is the appearance of an association in a subpopulation that is not seen in the general population. Pearl explores all of these paradoxes in light of causal diagrams, and I actually did find it helpful to view these problems with this causal lens. The causal diagrams were useful in generalizing the structure of the situations governing the paradoxes, which I think is helpful in recognizing when they occur. Further, Pearl lays forth a reasonable set of criteria for dealing with paradoxes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Any claim to resolve a paradox (especially one that is decades old)
should meet some basic criteria. First, as I said above in connection
with the Monty Hall paradox, it should explain why people find the
paradox surprising or unbelievable. Second, it should identify the
class of scenarios in which the paradox can occur. Third, it should
inform us of scenarios, if any, in which the paradox cannot occur.
Finally, when the paradox does occur, and we have to make a choice
between two plausible yet contradictory statements, it should tell us
which statement is correct. (p. 202)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;teaching-a-id-teaching-a&#34;&gt;Teaching &lt;a id=&#34;teaching&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;By its nature, the book aims to inform readers about the development of and about central ideas in causal inference, but teaching and pedagogy are not direct themes of the book. That being said, I was amazed at how appropriate the writing of the book is for a classroom textbook. There are a lot of great thought experiments, historical examples, and activities to engage students at the undergraduate level and beyond. In particular, the chapters that recount the evolution of the smoking-lung cancer debate (Chapter 5) and that explore &amp;ldquo;statistical&amp;rdquo; paradoxes through a causal lens (Chapter 6) are great sources of classroom content.&lt;/p&gt;

&lt;h2 id=&#34;conclusions-a-id-conclusions-a&#34;&gt;Conclusions &lt;a id=&#34;conclusions&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;I highly recommend this book to anyone who cares about science. Even if causal inference isn&amp;rsquo;t an area of interest for you, the ideas in this book are important for understanding the causal research that we otherwise consume or hear about. Pearl is very invested in these ideas, so the language in the book is very enthusiastically in favor of these methods. I can see how this might irritate some readers, but I found that the ideas he presented were compelling and interesting in their own right. Certainly these methods are not a panacea, but I do believe that they can be quite useful. Reading the book has motivated me to continue learning about these topics, and I hope that I can eventually fully understand the answers to some questions I was left with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Is there no reconciliation at all for Rubin causal model type methods and &lt;em&gt;do&lt;/em&gt;-calculus methods?&lt;/li&gt;
&lt;li&gt;How can causal diagrams and &lt;em&gt;do&lt;/em&gt;-calculus be used to study networks that evove with time?&lt;/li&gt;
&lt;li&gt;How is interference between units handled?&lt;/li&gt;
&lt;li&gt;How can we measure the causal effect of several variables simultaneously?&lt;/li&gt;
&lt;li&gt;I have heard of edges being random variables in the graphical model literature. (i.e. Arrows can point to arrows.) Is this part of the &lt;em&gt;do&lt;/em&gt;-calculus framework?&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

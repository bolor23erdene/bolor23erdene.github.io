<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.3.0">
  <meta name="generator" content="Hugo 0.62.2" />
  <meta name="author" content="Bolor-Erdene Zolbayar">

  
  
  
  
    
  
  <meta name="description" content="The goal of this paper is to train a machine learning model such that the ML system becomes resistance to adversarial examples. It is a well known fact that neural networks are vulnerable to adversarial examples. Some of the recent works explain that vulnerability of the neural networks is intrinsic. Madry et al. 2017 at MIT investigated how to create robust neural networks with robust optimization. As a result, they found a way to create successful attack and defense techniques based on robust optimization.">

  
  <link rel="alternate" hreflang="en-us" href="https://bolor23erdene.github.io/posts/pgd/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="https://bolor23erdene.github.io/index.xml" type="application/rss+xml" title="Bolor-Erdene Zolbayar">
  <link rel="feed" href="https://bolor23erdene.github.io/index.xml" type="application/rss+xml" title="Bolor-Erdene Zolbayar">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://bolor23erdene.github.io/posts/pgd/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Bolor-Erdene Zolbayar">
  <meta property="og:url" content="https://bolor23erdene.github.io/posts/pgd/">
  <meta property="og:title" content="Towards Deep Learning Models Resistant to Adversarial Attacks | Bolor-Erdene Zolbayar">
  <meta property="og:description" content="The goal of this paper is to train a machine learning model such that the ML system becomes resistance to adversarial examples. It is a well known fact that neural networks are vulnerable to adversarial examples. Some of the recent works explain that vulnerability of the neural networks is intrinsic. Madry et al. 2017 at MIT investigated how to create robust neural networks with robust optimization. As a result, they found a way to create successful attack and defense techniques based on robust optimization."><meta property="og:image" content="https://bolor23erdene.github.io/img/portrait.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-01-14T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2019-01-14T00:00:00&#43;00:00">
  

  

  

  <title>Towards Deep Learning Models Resistant to Adversarial Attacks | Bolor-Erdene Zolbayar</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Bolor-Erdene Zolbayar</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#research">
            
            <span>Research</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/journal">
            
            <span>Journal</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#certificates">
            
            <span>Certificates</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/sewards">
            
            <span>Services/Awards</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Towards Deep Learning Models Resistant to Adversarial Attacks</h1>

  

  
    

<div class="article-metadata">

  
  
  <span itemscope itemprop="author" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Bolor-Erdene Zolbayar">
  </span>
  

  <span class="article-date">
    
    <meta content="2019-01-14 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2019-01-14 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      Jan 14, 2019
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Bolor-Erdene Zolbayar">
  </span>

  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    
    <a href="">adversarial machine learning</a>, 
    
    <a href="/categories/research/">research</a>
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Towards%20Deep%20Learning%20Models%20Resistant%20to%20Adversarial%20Attacks&amp;url=https%3a%2f%2fbolor23erdene.github.io%2fposts%2fpgd%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fbolor23erdene.github.io%2fposts%2fpgd%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fbolor23erdene.github.io%2fposts%2fpgd%2f&amp;title=Towards%20Deep%20Learning%20Models%20Resistant%20to%20Adversarial%20Attacks"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fbolor23erdene.github.io%2fposts%2fpgd%2f&amp;title=Towards%20Deep%20Learning%20Models%20Resistant%20to%20Adversarial%20Attacks"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Towards%20Deep%20Learning%20Models%20Resistant%20to%20Adversarial%20Attacks&amp;body=https%3a%2f%2fbolor23erdene.github.io%2fposts%2fpgd%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    















  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      <p>The goal of this paper is to train a machine learning model such that the ML system becomes resistance to adversarial examples. It is a well known fact that neural networks are vulnerable to adversarial examples. Some of the recent works explain that vulnerability of the neural networks is intrinsic. Madry et al. 2017 at MIT investigated how to create robust neural networks with robust optimization. As a result, they found a way to create successful attack and defense techniques based on robust optimization. In this article, I will explain why they used robust optimization, how it worked, and what important techniques they used to create the robust neural networks.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#why">Why do they want to do robust optimization?</a></li>
<li><a href="#how">How were they able to achieve training that resulted high resistance to adversarial examples?</a></li>
<li><a href="#what">What are the some math behind this magic?</a></li>
</ol>
<h2 id="why-do-they-want-to-do-robust-optimization-a-idwhya"><em><strong>Why do they want to do robust optimization?</strong></em> <!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<ol>
<li>
<p>Growth in Machine Learning
Application of machine learning has been exponentially increasing in recent years following the development in high computational power and data availability. Recent breakthroughs in computer vision and speech recognition enable us to ride on a self-driving car, make a restaurant or haircut order without touching phone screen, and  search what you need on youtube or google simply telling a few words. A new research study <a href="https://www.marketwatch.com/press-release/global-machine-learning-market-2018-expected-to-reach-3998-billion-by-2025-and-research-analysis-done-by-technologies-types-2018-08-20">&ldquo;Machine Learning Market&rdquo;</a> states that the machine learning market is expected to grow from 1.3 billion USD in 2016 to 40 billion USD in 2025. For these reasons, security of machine learning has become one of the most important fields that needs to be studied.</p>
</li>
<li>
<p>Robust neural networks
Adversaries often create adversarial exmaples by modifying features of training examples that are close to decision boundary. To create a robust neural networks resistant to these adversarial examples, one technique is to create adversarial examples using training examples close to decision boundary and train the neural networks with them. As a result, the neural networks become more robust.</p>
</li>
<li>
<p>Why adversarial robust through robust optimization?
Previously, there were many defense techniques including defensive distillation, feature squeezing, and several others. They claim that these techniques don't offer a good understanding of the guarantees they provided. Their a natural saddle point formulation technique guarantees security to broad range of attacks. They were able to create attack and defense mechanisms with this technique. The adversarial training directly relates with optimizing the saddle point problem.</p>
</li>
</ol>
<h2 id="how-were-they-able-to-achieve-training-that-resulted-high-resistance-to-adversarial-examples-a-idhowa"><em><strong>How were they able to achieve training that resulted high resistance to adversarial examples?</strong></em> <!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>They make the following contributions:</p>
<ol>
<li>
<p>Optimization landscape study corresponding to saddle point formulation. Despite non-convexity and non-cavity of its constituent parts, they were able to track and solve the optimization problem using first-order methods. They created a projected gradient attack with the optimization technique using the first-order methods.</p>
</li>
<li>
<p>They found the model architecture capacity on adversarial robustness is important. To reliably withstand strong adversarial attacks, networks
require a significantly larger capacity than for correctly classifying benign examples only. This shows that a robust decision boundary of the saddle point problem can be significantly more complicated than a decision boundary that simply separates the benign data points.</p>
</li>
<li>
<p>Building on the above insights, we train networks on MNIST and CIFAR10 that are robust to
a wide range of adversarial attacks. Our approach is based on optimizing the aforementioned
saddle point formulation and uses our optimal “first-order adversary”. Our best MNIST model
achieves an accuracy of more than 89% against the strongest adversaries in our test suite. In
particular, our MNIST network is even robust against white box attacks of an iterative adversary.
Our CIFAR10 model achieves an accuracy of 46% against the same adversary. Furthermore,
in case of the weaker black box/transfer attacks, our MNIST and CIFAR10 networks achieve
the accuracy of more than 95% and 64%, respectively.</p>
</li>
</ol>
<h2 id="what-are-the-some-math-behind-this-magic-a-idwhata"><em><strong>What are the some math behind this magic?</strong></em> <!-- raw HTML omitted --><!-- raw HTML omitted --></h2>
<p>$ \theta \in \mathbb{R}^{d}$; D - training data distribution; $x \in \mathbb{R}^{d}$ training examples; $y \in [k]$ labels for corresponding
examples; $L(\theta,x,y)$ - loss function</p>
<h3 id="the-goal-is-to-minimize-the-risk-e_xy-sim-dlxytheta">*The goal is to minimize the risk: $E_{(x,y)} \sim D[L(x,y,\theta)]$*</h3>
<p>This ERM is great for classifiers. But, it doesn't provide resistance to adversarial examples</p>
<h3 id="how-to-make-it-robust"><em>How to make it robust?</em></h3>
<p>To make the model resistant, they augmented the ERM by following steps.</p>
<ol>
<li>They specify the attack model and make the classifier more robust to this specific attack.</li>
<li>For each training example x, they introduce set of perturbations $S \in \mathbb{R}^{d}$ that is  represented by the manipulative power of adversary</li>
<li>They modified the population risk $E_{d}[L]$ instead of feeding loss L with samples from original D distribution, they perturb the inputs. In this paper, they only focused on $l_{\infty}$ bounded attacks.</li>
</ol>
<p>They introduced the saddle point optimization problem. Inside is a maximization and outside is a minimization problem.</p>
<h3 id="challenges-and-solutions-to-them"><em>Challenges and solutions to them</em></h3>
<ul>
<li>
<p>The goal is to obtain a solution for $\mathop{min}_{\theta \in \mathbb{R}^{d}}E_{(x,y) \sim D} [\mathop{max}_{\delta \in S} L(\theta,x+\delta,y)]$</p>
</li>
<li>
<p>The inner part finding adversarial example is equivalent as maximizing highly non-concave function. Tool to solve this problem is PGD. PGD is a standard method for large-scale constrained optimization.</p>
</li>
<li>
<p>Important challenge is to obtain a good solution in a reasonable time.</p>
</li>
<li>
<p>Solving this problem requires non-convex outer minimization and non-concave inner maximization.</p>
</li>
<li>
<p>Their important contribution is to use PGD technique that solves the saddle point. They argue that loss landscape of the optimization problem is surprisingly tractable. The problem points towards projected gradient descent as the ultimate first order adversary.</p>
</li>
<li>
<p>Finding significantly low loss function after solving the optimization problem guarantees the classifier is resistant to adversarial examples.</p>
</li>
<li>
<p>They argue that the minimzation of the outer function in terms of \theta parameters is equivalent as solving the problem with stochastic gradient descent using the gradients solved by the inner maximization problem.</p>
</li>
<li>
<p>Basically, they stated that if the network is trained to be robust against PGD adversaries, it will be robust against a wide range of attacks that encompasses all current approaches.</p>
</li>
</ul>
<h3 id="they-found-following-phenomena-during-their-experiments"><em>They found following phenomena during their experiments</em></h3>
<ul>
<li>
<p>the loss achieved by the adversary increases in a fairly consistent way and plateaus rapidly when performing projected $l_{\infty}$ gradient descent for randomly chosen starting points inside $x + S$</p>
</li>
<li>
<p>Investigating the concentration of maxima further, they observed that over a large number of random restarts, the loss of the final iterate follows a well-concentrated distribution without extreme outliers.</p>
</li>
<li>
<p>By applying SGD using the gradient descent of the loss at adversarial examples they can consistently reduced the loss of the saddle point problem during training.</p>
</li>
</ul>
<p><img src="/static/PGD/loss.png" alt="This is an image"></p>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/review/">review</a>
  
</div>



    






<div class="media author-card" itemscope itemtype="http://schema.org/Person">
  
  <img class="portrait mr-3" src="/img/portrait.jpg" itemprop="image" alt="Avatar">
  
  <div class="media-body">
    <h5 class="card-title" itemprop="name"><a href="/">Bolor-Erdene Zolbayar</a></h5>
    <h6 class="card-subtitle">Graduate Research Assistant</h6>
    
    <ul class="network-icon" aria-hidden="true">
      
      
      
      
        
      
      
      
      
      
      <li>
        <a itemprop="sameAs" href="mailto:bzz5065@psu.edu" >
          <i class="fas fa-envelope"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://twitter.com/bolor23erdene" target="_blank" rel="noopener">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
      
      
      
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://scholar.google.com/citations?user=3lh0e_AAAAAJ&amp;hl=en" target="_blank" rel="noopener">
          <i class="ai ai-google-scholar"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://github.com/bolor23erdene" target="_blank" rel="noopener">
          <i class="fab fa-github"></i>
        </a>
      </li>
      
    </ul>
  </div>
</div>




    
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    © 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    <script src="/js/academic.min.f127949ece415114366a1099069e0f81.js"></script>

    

    

  
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
  

  

  

  <script>hljs.initHighlightingOnLoad();</script>
  

  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous"></script>
  
  


  </body>
</html>

